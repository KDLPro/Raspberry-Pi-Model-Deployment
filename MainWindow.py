# Form implementation generated from reading ui file 'FiberWatch_App.ui'
#
# Created by: PyQt6 UI code generator 6.4.2
#
# WARNING: Any manual changes made to this file will be lost when pyuic6 is
# run again.  Do not edit this file unless you know what you are doing.

import os, traceback, sys, shutil

from Dialog import Ui_Dialog

from PyQt6 import QtCore, QtGui, QtWidgets
from PyQt6.QtWidgets import QFileDialog, QGraphicsScene, QDialog, QGraphicsPixmapItem, QMessageBox
from PyQt6.QtGui import QPixmap, QImage, QMovie
from PyQt6.QtCore import Qt, QRunnable, QThreadPool, pyqtSignal, QObject, pyqtSlot
import traceback

import cv2

from PIL import Image

import ffmpeg

from ultralytics import YOLO

from supabase import create_client

import matplotlib.pyplot as plt
from matplotlib.backends.backend_agg import FigureCanvasAgg
import numpy as np

import Keys

class WorkerSignals(QObject):
    '''
    Defines the signals available from a running worker thread.

    Supported signals are:

    finished
        No data

    error
        tuple (exctype, value, traceback.format_exc() )

    result
        object data returned from processing, anything

    '''
    finished = pyqtSignal()
    error = pyqtSignal(tuple)
    result = pyqtSignal(object)

class Worker(QRunnable):
    '''
    Worker thread

    Inherits from QRunnable to handler worker thread setup, signals and wrap-up.

    :param callback: The function callback to run on this worker thread. Supplied args and
                     kwargs will be passed through to the runner.
    :type callback: function
    :param args: Arguments to pass to the callback function
    :param kwargs: Keywords to pass to the callback function

    '''

    def __init__(self, function, *args, **kwargs):
        super().__init__()

        # Constructor arguments
        self.function = function
        self.args = args
        self.kwargs = kwargs
        self.signals = WorkerSignals()

    @pyqtSlot()
    def run(self):
        '''
        Initialise the runner function with passed args, kwargs.
        '''

        try:
            result = self.function(*self.args, **self.kwargs)
        except:
            traceback.print_exc()
            exctype, value = sys.exc_info()[:2]
            self.signals.error.emit((exctype, value, traceback.format_exc()))
        else:
            self.signals.result.emit(result)  # Return the result of the processing
        finally:
            self.signals.finished.emit()  # Done

class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(1024, 550)
        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Fixed, QtWidgets.QSizePolicy.Policy.Fixed)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(MainWindow.sizePolicy().hasHeightForWidth())
        MainWindow.setSizePolicy(sizePolicy)
        MainWindow.setMinimumSize(QtCore.QSize(1024, 550))
        MainWindow.setMaximumSize(QtCore.QSize(1024, 550))
        palette = QtGui.QPalette()
        brush = QtGui.QBrush(QtGui.QColor(0, 170, 69))
        brush.setStyle(QtCore.Qt.BrushStyle.SolidPattern)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.Button, brush)
        brush = QtGui.QBrush(QtGui.QColor(255, 255, 255))
        brush.setStyle(QtCore.Qt.BrushStyle.SolidPattern)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.Window, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.Button, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.Window, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Disabled, QtGui.QPalette.ColorRole.Base, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Disabled, QtGui.QPalette.ColorRole.Window, brush)
        brush = QtGui.QBrush(QtGui.QColor(184, 200, 188))
        brush.setStyle(QtCore.Qt.BrushStyle.SolidPattern)
        palette.setBrush(QtGui.QPalette.ColorGroup.Disabled, QtGui.QPalette.ColorRole.Button, brush)
        MainWindow.setPalette(palette)
        font = QtGui.QFont()
        font.setFamily("Satoshi")
        font.setPointSize(12)
        font.setBold(False)
        MainWindow.setFont(font)
        icon = QtGui.QIcon()
        icon.addPixmap(QtGui.QPixmap("icons/logo.png"), QtGui.QIcon.Mode.Normal, QtGui.QIcon.State.Off)
        MainWindow.setWindowIcon(icon)
        MainWindow.setStyleSheet("")
        MainWindow.setIconSize(QtCore.QSize(48, 48))
        self.centralwidget = QtWidgets.QWidget(parent=MainWindow)
        self.centralwidget.setStyleSheet("border-bottom: 1px solid rgb(0, 170, 69);")
        self.centralwidget.setObjectName("centralwidget")
        self.title_label = QtWidgets.QLabel(parent=self.centralwidget)
        self.title_label.setGeometry(QtCore.QRect(412, 10, 200, 31))
        font = QtGui.QFont()
        font.setFamily("Satoshi Medium")
        font.setPointSize(24)
        font.setBold(True)
        self.title_label.setFont(font)
        self.title_label.setStyleSheet("color: rgb(0, 85, 0)")
        self.title_label.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        self.title_label.setObjectName("title_label")
        self.image_or_video = QtWidgets.QGraphicsView(parent=self.centralwidget)
        self.image_or_video.setGeometry(QtCore.QRect(50, 120, 410, 350))
        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Fixed, QtWidgets.QSizePolicy.Policy.Fixed)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.image_or_video.sizePolicy().hasHeightForWidth())
        self.image_or_video.setSizePolicy(sizePolicy)
        self.image_or_video.setMaximumSize(QtCore.QSize(410, 350))
        self.image_or_video.setStyleSheet("background-color: #AFBE87")
        self.image_or_video.setFrameShape(QtWidgets.QFrame.Shape.Box)
        self.image_or_video.setFrameShadow(QtWidgets.QFrame.Shadow.Plain)
        self.image_or_video.setLineWidth(1)
        self.image_or_video.setObjectName("image")
        self.graph = QtWidgets.QGraphicsView(parent=self.centralwidget)
        self.graph.setGeometry(QtCore.QRect(564, 120, 410, 350))
        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Fixed, QtWidgets.QSizePolicy.Policy.Fixed)
        self.graph.setHorizontalScrollBarPolicy(QtCore.Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        self.graph.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.graph.sizePolicy().hasHeightForWidth())
        self.graph.setSizePolicy(sizePolicy)
        self.graph.setMaximumSize(QtCore.QSize(410, 350))
        self.graph.setStyleSheet("background-color: #AFBE87")
        self.graph.setFrameShape(QtWidgets.QFrame.Shape.Box)
        self.graph.setFrameShadow(QtWidgets.QFrame.Shadow.Plain)
        self.graph.setLineWidth(1)
        self.graph.setObjectName("graph")
        self.label_2 = QtWidgets.QLabel(parent=self.centralwidget)
        self.label_2.setGeometry(QtCore.QRect(205, 80, 100, 30))
        font = QtGui.QFont()
        font.setFamily("Satoshi Medium")
        font.setPointSize(18)
        font.setBold(True)
        self.label_2.setFont(font)
        self.label_2.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        self.label_2.setObjectName("label_2")
        self.label_3 = QtWidgets.QLabel(parent=self.centralwidget)
        self.label_3.setGeometry(QtCore.QRect(704, 80, 130, 30))
        font = QtGui.QFont()
        font.setFamily("Satoshi Medium")
        font.setPointSize(18)
        font.setBold(True)
        self.label_3.setFont(font)
        self.label_3.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        self.label_3.setObjectName("label_3")
        self.open = QtWidgets.QPushButton(parent=self.centralwidget)
        self.open.setGeometry(QtCore.QRect(350, 80, 110, 30))
        palette = QtGui.QPalette()
        brush = QtGui.QBrush(QtGui.QColor(255, 255, 255))
        brush.setStyle(QtCore.Qt.BrushStyle.SolidPattern)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.Light, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.ButtonText, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.Light, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.ButtonText, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Disabled, QtGui.QPalette.ColorRole.Light, brush)
        self.open.setPalette(palette)
        font = QtGui.QFont()
        font.setFamily("Satoshi Medium")
        font.setPointSize(12)
        font.setBold(True)
        self.open.setFont(font)
        self.open.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")
        self.open.setObjectName("loadImage")
        self.predict = QtWidgets.QPushButton(parent=self.centralwidget)
        self.predict.setGeometry(QtCore.QRect(350, 480, 110, 30))
        palette = QtGui.QPalette()
        brush = QtGui.QBrush(QtGui.QColor(255, 255, 255))
        brush.setStyle(QtCore.Qt.BrushStyle.SolidPattern)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.Light, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.ButtonText, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.Light, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.ButtonText, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Disabled, QtGui.QPalette.ColorRole.Light, brush)
        self.predict.setPalette(palette)
        font = QtGui.QFont()
        font.setFamily("Satoshi Medium")
        font.setPointSize(12)
        font.setBold(True)
        self.predict.setFont(font)
        self.predict.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")
        self.predict.setObjectName("predict")
        self.listWidget = QtWidgets.QListWidget(parent=self.centralwidget)
        self.listWidget.setGeometry(QtCore.QRect(350, 109, 110, 50))
        palette = QtGui.QPalette()
        brush = QtGui.QBrush(QtGui.QColor(255, 255, 255))
        brush.setStyle(QtCore.Qt.BrushStyle.SolidPattern)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.Light, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Active, QtGui.QPalette.ColorRole.Text, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.Light, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Inactive, QtGui.QPalette.ColorRole.Text, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Disabled, QtGui.QPalette.ColorRole.Light, brush)
        palette.setBrush(QtGui.QPalette.ColorGroup.Disabled, QtGui.QPalette.ColorRole.Text, brush)
        self.listWidget.setPalette(palette)
        font = QtGui.QFont()
        font.setFamily("Satoshi Medium")
        font.setPointSize(12)
        font.setBold(True)
        self.listWidget.setFont(font)
        self.listWidget.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); color: rgb(255, 255, 255);}\n"
            "QListWidget::item:hover{background-color: rgb(134, 80, 46);} QListWidget::item:hover:selected{background-color: rgb(134, 80, 46);}"
            "QListWidget::item:selected{background-color: rgb(0, 170, 69); color: rgb(255, 255, 255);}")
        self.listWidget.setObjectName("listWidget")
        item = QtWidgets.QListWidgetItem()
        self.listWidget.addItem(item)
        item = QtWidgets.QListWidgetItem()
        self.listWidget.addItem(item)
        self.listWidget.hide()
        self.listWidget.itemClicked.connect(self.openListWidgetClicked)
        MainWindow.setCentralWidget(self.centralwidget)
        self.statusbar = QtWidgets.QStatusBar(parent=MainWindow)
        self.statusbar.setObjectName("statusbar")
        font.setFamily("Satoshi")
        font.setPointSize(11)
        font.setBold(True)
        self.statusbar.setFont(font)
        self.statusbar.setStyleSheet("background-color: rgb(240, 250, 240);")
        MainWindow.setStatusBar(self.statusbar)
        self.img_or_vid_scene = QGraphicsScene()
        self.graph_scene = QGraphicsScene()
        self.video_pixmap_item = QGraphicsPixmapItem()

        # Buttons to functions
        self.open.clicked.connect(self.openMenu)
        self.predict.clicked.connect(self.generatePreds)

        # Threads
        self.thread_manager = QThreadPool()

        # Variables
        self.imgPath = ""
        self.vidPath = ""
        self.video_cap, self.vidDisplay, self.movie = None, None, None
        self.gif_frames = []
        self.current_frame_idx = 0
        self.grade_s2 = [0]
        self.grade_s3 = [0]
        self.length_grades = [0]
        self.offline = False

        # Call supabase client
        self.initSupabaseClient()

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def initSupabaseClient(self):
        try:
            self.supabase = create_client(Keys.url, Keys.key)

            # Set system status to online
            response = (
                        self.supabase.table("system_status")
                        .insert({"online": True, "alert_code": 101})
                        .execute()
                    )
        except:
            self.activateOfflineMode()

    def openMenu(self):
        self.listWidget.show()

    def openListWidgetClicked(self, clickedItem):
        if (clickedItem.text() == "Open Image"):
            self.openImage()
        elif (clickedItem.text() == "Open Video"):
            self.openVideo()

    def openImage(self):
        if self.video_cap != None:
            self.video_cap.release()
        if self.movie != None:
            self.movie.stop()
        self.movie = None
        self.listWidget.hide()
        self.open.setDisabled(True)
        self.predict.setDisabled(True)
        self.open.setStyleSheet("QWidget{background-color: rgb(0, 236, 96); border: none;} QToolTip {background-color: white;}")

        # Load image
        self.imgPath, _ = QFileDialog.getOpenFileName(self, caption="Open Image", filter="Image Files (*.png *.jpg *.bmp)")
        self.vidPath = ""

        _translate = QtCore.QCoreApplication.translate
        self.label_2.setText(_translate("MainWindow", "Image"))

        if (self.imgPath == ""):
            self.loadImageFail()
            return
        
        self.update_status("Loading image...")

        # Create a worker to handle loading image
        worker = Worker(self.processImage)

        worker.signals.result.connect(self.displayImage)
        worker.signals.error.connect(self.loadImageFail)
        worker.signals.finished.connect(self.img_load_done)

        # Start the worker
        self.thread_manager.start(worker)

    def processImage(self):
        try: 
            self.update_status("Processing image...")

            cv_image = cv2.imread(self.imgPath, cv2.IMREAD_UNCHANGED)

            # Clear scene
            self.img_or_vid_scene.clear()
            self.image_or_video.resetTransform()

            # Resize image using OpenCV
            view_width = self.image_or_video.width() - 2
            view_height = self.image_or_video.height() - 2
            
            original_width = cv_image.shape[1]
            original_height = cv_image.shape[0]

            width_scale = view_width / original_width
            height_scale = view_height / original_height

            scale_factor = min(width_scale, height_scale)

            new_width = int(original_width * scale_factor)
            new_height = int(original_height * scale_factor)

            # Resize the image with OpenCV while maintaining the aspect ratio
            resized_cv_image = cv2.resize(cv_image, (new_width, new_height))

            # Check if the image has 4 channels (RGBA) or 3 channels (RGB)
            if resized_cv_image.shape[2] == 4: 
                resized_cv_image_rgb = cv2.cvtColor(resized_cv_image, cv2.COLOR_BGRA2RGBA)
            else:  
                resized_cv_image_rgb = cv2.cvtColor(resized_cv_image, cv2.COLOR_BGR2RGB)

            return resized_cv_image_rgb  # Pass processed image back to main thread

        except Exception as e:
            raise e  # Worker will emit error signal

    def displayImage(self, resized_cv_image_rgb):
        try:
            # Convert the OpenCV image to QImage
            height, width, channel = resized_cv_image_rgb.shape
            bytes_per_line = 3 * width if channel == 3 else 4 * width  # 3 for RGB, 4 for RGBA
            qimage = QImage(resized_cv_image_rgb.data, width, height, bytes_per_line, QImage.Format.Format_RGB888 if channel == 3 else QImage.Format.Format_RGBA8888)
            scaledPixmap = QPixmap.fromImage(qimage)
            
            # Display image in the graphics window
            pixmap_item = QGraphicsPixmapItem(scaledPixmap)
            self.image_or_video.setStyleSheet("background-color: #FFFFFF")

            self.img_or_vid_scene.clear()
            self.img_or_vid_scene.addItem(pixmap_item)
            self.image_or_video.fitInView(self.img_or_vid_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
            self.image_or_video.centerOn(255, 295)
            self.image_or_video.setAlignment(Qt.AlignmentFlag.AlignCenter)
            self.image_or_video.setScene(self.img_or_vid_scene)

            self.statusbar.clearMessage()

        except Exception as e:
            print("Loading image failed.")

    def loadImageFail(self):
        # Clears the graphics view and status bar when image loading has failed, and resets variables
        self.statusbar.clearMessage()
        self.open.setDisabled(False)
        self.predict.setDisabled(False)
        AlertImage()
        self.resetScene()

    def openVideo(self):
        if self.video_cap != None:
            self.video_cap.release()
        if self.movie != None:
            self.movie.stop()
        self.movie = None
        self.listWidget.hide()
        self.open.setDisabled(True)
        self.predict.setDisabled(True)
        self.open.setStyleSheet("QWidget{background-color: rgb(0, 236, 96); border: none;} QToolTip {background-color: white;}")

        # Load image
        self.vidPath, _ = QFileDialog.getOpenFileName(self, caption="Open Video", filter="Video Files (*.mp4 *.flv *.ts *.mts *.avi)")
        self.imgPath = ""

        _translate = QtCore.QCoreApplication.translate
        self.label_2.setText(_translate("MainWindow", "Video"))

        if (self.vidPath == ""):
            self.loadVideoFail()
            return
        
        self.update_status("Loading video...")

        # Create a worker to handle loading video
        worker = Worker(self.processVideo)

        worker.signals.result.connect(self.displayVideo)
        worker.signals.error.connect(self.loadVideoFail)
        worker.signals.finished.connect(self.video_load_done)

        # Start the worker
        self.thread_manager.start(worker)
        
    def processVideo(self):
        try: 
            self.update_status("Processing video...")

            self.video_cap = cv2.VideoCapture(self.vidPath)
            video_fps = self.video_cap.get(cv2.CAP_PROP_FPS)
            target_fps = 30  # Desired FPS for the GIF
            video_frame_interval = int(1000 / target_fps)  # Interval in milliseconds for 30 FPS

            frames = []
            frame_count = 0
            while True:
                ret, frame = self.video_cap.read()
                if not ret:
                    break

                # Downsample or skip frames to match 30 FPS
                if video_fps > target_fps:
                    if frame_count % int(video_fps / target_fps) == 0:
                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        frames.append(frame)
                else:
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frames.append(frame)

                frame_count += 1
                if frame_count == 1:
                    self.update_status("Processing video: " + str(frame_count) + " frame processed")
                else:
                    self.update_status("Processing video: " + str(frame_count) + " frames processed")

            # Convert frames to GIF using Pillow
            self.createGIF(frames)

            return video_frame_interval

        except Exception as e:
            raise e  # Worker will emit error signal
        
    def createGIF(self, frames):
        try:
            pil_frames = []
            total_frames = len(frames)
            for i in range(total_frames):
                pil_image = Image.fromarray(frames[i])
                self.update_status(f"Processing frame {i + 1} of {total_frames} for display...")
                # Resize the image to 410x350
                pil_image = pil_image.resize((408, 348), Image.Resampling.LANCZOS)
                pil_frames.append(pil_image)

            self.update_status("Combining frames for display...")   
            gif_path = "__pycache__/output.gif"
            pil_frames[0].save(gif_path, save_all=True, append_images=pil_frames[1:], duration=100, loop=0)
            self.gif_frames = pil_frames
        except Exception as e:
            raise e
        
    def displayVideo(self):
        try:
            self.update_status("Displaying video...")   
            self.img_or_vid_scene.clear()
            
            self.movie = QMovie("__pycache__/output.gif")
        
            # Create a QGraphicsPixmapItem to display the GIF version of the video
            self.gif_pixmap_item = QGraphicsPixmapItem()
            self.img_or_vid_scene.addItem(self.gif_pixmap_item)
            self.image_or_video.setScene(self.img_or_vid_scene)
            self.movie.frameChanged.connect(self.updateFrame)
            
            # Start playing the GIF (this will loop automatically)
            self.movie.start()

            self.statusbar.clearMessage()

        except Exception as e:
            raise e  # Worker will emit error signal
        
    def updateFrame(self):
        # This function is called whenever the QMovie updates the frame.
        current_frame = self.movie.currentPixmap()  # Get the current frame as QPixmap
        self.gif_pixmap_item.setPixmap(current_frame)  # Update the pixmap in the scene

    def pilToQImage(self, pil_image):
        """Convert a PIL image to QImage."""
        img_data = pil_image.tobytes("raw", "RGB")
        return QImage(img_data, pil_image.width, pil_image.height, QImage.Format.Format_RGB888)

    def loadVideoFail(self):
        # Clears the graphics view and status bar when image loading has failed, and resets variables
        self.statusbar.clearMessage()
        self.open.setDisabled(False)
        self.predict.setDisabled(False)
        AlertVideo()
        self.resetScene()

    def resetScene(self):
        self.img_or_vid_scene.clear()
        self.image_or_video.setStyleSheet("background-color: #AFBE87")
        self.imgPath = ""
        self.vidPath = ""
        _translate = QtCore.QCoreApplication.translate
        self.label_2.setText(_translate("MainWindow", "File"))
        self.disableOpenMenu()

    def generatePreds(self):
        if self.imgPath != "" or self.vidPath != "":
            self.predict.setDisabled(True)
            self.open.setDisabled(True)
            self.predict.setStyleSheet("QWidget{background-color: rgb(0, 236, 96); border: none;} QToolTip {background-color: white;}")
            if self.video_cap != None:
                self.video_cap.release()
            if self.movie != None:
                self.movie.stop()
            self.movie = None

            # Create a worker to handle predictions
            worker = Worker(self.loadModelAndPredict)

            if self.imgPath != "" or self.vidPath == "":              # If image is loaded
                self.update_status("Processing image...")
                worker.signals.result.connect(self.handleImgPredResult)
                worker.signals.finished.connect(self.img_prediction_done)
            elif self.imgPath == "" or self.vidPath != "":              # If video is loaded
                self.update_status("Processing video...")
                worker.signals.result.connect(self.handleVidPredResult)
                worker.signals.finished.connect(self.vid_prediction_done)

            worker.signals.error.connect(self.predictionFail)

            # Start the worker
            self.thread_manager.start(worker)
        else:               # No image or video loaded
            AlertNoItemLoaded()
        
    def loadModelAndPredict(self):
        curr_dir = os.getcwd()
        custom_save_dir = os.path.join(curr_dir, "results")
        custom_save_dir = os.path.normpath(custom_save_dir)
        
        # Remove the custom save directory if it exists, then remake it
        try:
            shutil.rmtree(custom_save_dir)
            print(f"Folder '{custom_save_dir}' and all its contents have been deleted.")
        except OSError as e:
            print(f"Error: {e.strerror}.")

        os.makedirs(custom_save_dir, exist_ok=True)

        # Load a YOLO11n PyTorch model and export to NCNN format
        
        if (os.path.exists("models/November-23_ncnn_model") == False):
            model = YOLO("models/November-23.pt")
            model.export(format="ncnn") 

        ncnn_model = YOLO("models/November-23_ncnn_model", task="detect")

        if self.imgPath != "" or self.vidPath == "":              # If image is loaded
            results = ncnn_model.predict(self.imgPath, project=custom_save_dir, save=True, exist_ok=True, save_txt=True, iou=0.2, agnostic_nms=True)

            # Get image location
            base_img = os.path.basename(self.imgPath)
            final_img = os.path.join(custom_save_dir, "predict", base_img)
            final_img = os.path.normpath(final_img) 

            # Get labels location
            img_without_ext = os.path.splitext(base_img)[0]
            labels_dir = os.path.join(custom_save_dir, "predict", "labels")
            labels_dir = os.path.normpath(labels_dir)
            txt_file = os.path.join(labels_dir, f"{img_without_ext}.txt")
            txt_file = os.path.normpath(txt_file)

            return [final_img, txt_file]
        
        elif self.imgPath == "" or self.vidPath != "":              # If video is loaded
            results = ncnn_model.predict(self.vidPath, project=custom_save_dir, save=True, exist_ok=True, save_txt=True, iou=0.2, agnostic_nms=True)

            # Get video location
            base_vid = os.path.basename(self.vidPath)
            vid_without_ext = os.path.splitext(base_vid)[0]
            final_vid_avi = os.path.join(custom_save_dir, "predict", vid_without_ext + ".avi")
            final_vid_avi = os.path.normpath(final_vid_avi) 
            final_vid_mp4 = os.path.join(custom_save_dir, "predict", vid_without_ext + ".mp4")
            final_vid_mp4 = os.path.normpath(final_vid_mp4) 

            try:
                self.update_status("Converting resulting video to mp4...")
                # Use FFmpeg to convert the AVI to MP4
                ffmpeg.input(final_vid_avi).output(final_vid_mp4, vcodec='libx264', acodec='aac').run()
                self.update_status("Converting result video successful!")
            except ffmpeg.Error as e:
                print(f"Error converting video: {e}")

            self.vidPath = final_vid_mp4

            # Get labels directory
            labels_dir = os.path.join(custom_save_dir, "predict", "labels")
            labels_dir = os.path.normpath(labels_dir)

            return labels_dir

    def handleImgPredResult(self, result_arr):
        try: 
            # Process image first
            cv_image = cv2.imread(result_arr[0], cv2.IMREAD_UNCHANGED)

            # Resize image using OpenCV
            view_width = self.image_or_video.width() - 2
            view_height = self.image_or_video.height() - 2
            
            original_width = cv_image.shape[1]
            original_height = cv_image.shape[0]

            width_scale = view_width / original_width
            height_scale = view_height / original_height

            scale_factor = min(width_scale, height_scale)

            new_width = int(original_width * scale_factor)
            new_height = int(original_height * scale_factor)

            # Resize the image with OpenCV while maintaining the aspect ratio
            resized_cv_image = cv2.resize(cv_image, (new_width, new_height))

            # Check if the image has 4 channels (RGBA) or 3 channels (RGB)
            if resized_cv_image.shape[2] == 4: 
                resized_cv_image_rgb = cv2.cvtColor(resized_cv_image, cv2.COLOR_BGRA2RGBA)
            else:  
                resized_cv_image_rgb = cv2.cvtColor(resized_cv_image, cv2.COLOR_BGR2RGB)

            # Convert the OpenCV image to QImage
            height, width, channel = resized_cv_image_rgb.shape
            bytes_per_line = 3 * width if channel == 3 else 4 * width  # 3 for RGB, 4 for RGBA
            qimage = QImage(resized_cv_image_rgb.data, width, height, bytes_per_line, QImage.Format.Format_RGB888 if channel == 3 else QImage.Format.Format_RGBA8888)
            scaledPixmap = QPixmap.fromImage(qimage)
            
            # Display image in the graphics window
            pixmap_item = QGraphicsPixmapItem(scaledPixmap)
            self.image_or_video.setStyleSheet("background-color: #FFFFFF")

            self.img_or_vid_scene.clear()
            self.img_or_vid_scene.addItem(pixmap_item)
            self.image_or_video.fitInView(self.img_or_vid_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
            self.image_or_video.centerOn(255, 295)
            self.image_or_video.setAlignment(Qt.AlignmentFlag.AlignCenter)
            self.image_or_video.setScene(self.img_or_vid_scene)

            # Get data about the classification results
            grade_indices = []
            with open(result_arr[1], "r") as file:
                for line in file:
                    tokens = line.split()
                    if tokens and tokens[0].isdigit():
                        grade_indices.append(int(tokens[0]))
                    elif tokens:  # Try converting non-integer numbers (e.g., float)
                        try:
                            grade_indices.append(float(tokens[0]))
                        except ValueError:
                            pass

            grades = [0, 0]
            for i in grade_indices:
                if i == 0:          # Grade S2
                    grades[0] += 1
                elif i == 1:        # Grade S3
                    grades[1] += 1

            if self.offline == False:
                # Uploading results to Supabase
                self.update_status("Uploading results to Supabase database...")
                for i in range(2):
                    if i == 0:
                        self.grade_s2.append(grades[0])
                    else:
                        self.grade_s3.append(grades[1])
                    if grades[i] == 0:
                        continue
                    grade_code = "S2" if (i == 1) else "S3"
                    response = (
                        self.supabase.table("fiber_scanning_logs")
                        .insert({"fiber_grade": grade_code, "number_of_fibers": grades[i]})
                        .execute()
                    )

            self.length_grades.append(len(self.length_grades))

            # Display graph
            self.update_status("Displaying graph...")

            SatoshiLabel = {
                "family" : "Satoshi",
                "color":  "#006328",
                "weight": "medium",
                "size": 12,
            }

            # Initialize graph

            # Desired pixel dimensions
            width_px = 820
            height_px = 700
            dpi = 250  # Adjust DPI as needed

            # Convert pixel dimensions to inches
            width_in = width_px / dpi
            height_in = height_px / dpi

            # Create the figure
            fig, ax = plt.subplots(figsize=(width_in, height_in), dpi=dpi)
            ax.plot(self.length_grades, self.grade_s2, label = "Grade S2", color = "#D0C7AA")
            ax.plot(self.length_grades, self.grade_s3, label = "Grade S3", color = "#825B43")
            ax.set_ylabel("Number of Fibers", fontdict = SatoshiLabel, labelpad=5)
            ax.tick_params(axis = "both", labelsize = 10, labelfontfamily = "Satoshi")
            ax.legend()
            plt.tight_layout(pad=1)

            # Convert to cv2 image
            canvas = FigureCanvasAgg(fig)
            canvas.draw()
            fig.tight_layout()
            buf = canvas.buffer_rgba()
            image = np.asarray(buf)
            image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            resized_image = cv2.resize(image_bgr, (410, 350))
            height, width, channels = resized_image.shape
            qimage = QImage(resized_image.data, width, height, 3 * width, QImage.Format.Format_BGR888)
            pixmap = QPixmap.fromImage(qimage)

            # Display graph
            pixmap_item = self.graph_scene.addPixmap(pixmap)
            pixmap_item.setTransformationMode(Qt.TransformationMode.SmoothTransformation)
            self.graph.fitInView(pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
            self.graph.setScene(self.graph_scene)

            plt.close(fig)

        except Exception as e:
            self.predictionFail()

    def handleVidPredResult(self, labels_dir):
        self.img_or_vid_scene.clear()

        for filename in os.listdir(labels_dir):
        # Check if the file has a .txt extension
            if filename.endswith('.txt'):
                file_path = os.path.join(labels_dir, filename)
                try:
                    grade_indices = []
                    with open(file_path, "r") as file:
                        for line in file:
                            tokens = line.split()
                            if tokens and tokens[0].isdigit():
                                grade_indices.append(int(tokens[0]))
                            elif tokens:  # Try converting non-integer numbers (e.g., float)
                                try:
                                    grade_indices.append(float(tokens[0]))
                                except ValueError:
                                    pass

                    grades = [0, 0]
                    for i in grade_indices:
                        if i == 0:          # Grade S2
                            grades[0] += 1
                        elif i == 1:        # Grade S3
                            grades[1] += 1

                    if self.offline == False:
                        # Uploading results to Supabase
                        self.update_status("Uploading results to Supabase database...")
                        for i in range(2):
                            if i == 0:
                                self.grade_s2.append(grades[0])
                            else:
                                self.grade_s3.append(grades[1])
                            if grades[i] == 0:
                                continue
                            grade_code = "S2" if (i == 1) else "S3"
                            response = (
                                self.supabase.table("fiber_scanning_logs")
                                .insert({"fiber_grade": grade_code, "number_of_fibers": grades[i]})
                                .execute()
                            )

                    self.length_grades.append(len(self.length_grades))
                except Exception as e:
                    print(f"Error reading {filename}: {e}")

        # Display graph
        self.update_status("Displaying graph...")

        SatoshiLabel = {
            "family" : "Satoshi",
            "color":  "#006328",
            "weight": "medium",
            "size": 12,
        }

        # Initialize graph

        # Desired pixel dimensions
        width_px = 820
        height_px = 700
        dpi = 250  # Adjust DPI as needed

        # Convert pixel dimensions to inches
        width_in = width_px / dpi
        height_in = height_px / dpi

        # Create the figure
        fig, ax = plt.subplots(figsize=(width_in, height_in), dpi=dpi)
        ax.plot(self.length_grades, self.grade_s2, label = "Grade S2", color = "#D0C7AA")
        ax.plot(self.length_grades, self.grade_s3, label = "Grade S3", color = "#825B43")
        ax.set_ylabel("Number of Fibers", fontdict = SatoshiLabel, labelpad=5)
        ax.tick_params(axis = "both", labelsize = 10, labelfontfamily = "Satoshi")
        ax.legend()
        plt.tight_layout(pad=1)

        # Convert to cv2 image
        canvas = FigureCanvasAgg(fig)
        canvas.draw()
        fig.tight_layout()
        buf = canvas.buffer_rgba()
        image = np.asarray(buf)
        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        resized_image = cv2.resize(image_bgr, (410, 350))
        height, width, channels = resized_image.shape
        qimage = QImage(resized_image.data, width, height, 3 * width, QImage.Format.Format_BGR888)
        pixmap = QPixmap.fromImage(qimage)

        # Display graph
        pixmap_item = self.graph_scene.addPixmap(pixmap)
        pixmap_item.setTransformationMode(Qt.TransformationMode.SmoothTransformation)
        self.graph.fitInView(pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        self.graph.setScene(self.graph_scene)

        print(self.grade_s2)
        print(self.grade_s3)

    def predictionFail(self):
        # Clears the graphics view and status bar when image loading has failed, and resets variables
        self.statusbar.clearMessage()
        AlertPrediction()
        self.open.setDisabled(False)
        self.predict.setDisabled(False)
        self.predict.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")

    def img_load_done(self):
        self.update_status("Image loaded successfully!", timeout = 2000)
        self.open.setDisabled(False)
        self.predict.setDisabled(False)
        self.open.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")

    def video_load_done(self):
        self.update_status("Video loaded successfully!", timeout = 2000)
        self.open.setDisabled(False)
        self.predict.setDisabled(False)
        self.open.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")

    def img_prediction_done(self):
        self.update_status("Prediction done!", timeout = 2000)
        self.open.setDisabled(False)
        self.predict.setDisabled(False)
        self.predict.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")
        self.imgPath = ""

    def vid_prediction_done(self):
        self.update_status("Loading video...")
        self.start_video_processing()

    def start_video_processing(self):

        # Create a worker to handle loading video
        worker = Worker(self.processVideo)

        worker.signals.result.connect(self.displayVideo)
        worker.signals.error.connect(self.loadVideoFail)
        worker.signals.finished.connect(self.pred_video_load_done)

        # Start the worker
        self.thread_manager.start(worker)

    def pred_video_load_done(self):
        self.update_status("Prediction done!", timeout = 2000)
        self.open.setDisabled(False)
        self.predict.setDisabled(False)
        self.predict.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")
        self.vidPath = ""
        
    def disableOpenMenu(self):
        self.open.setDisabled(False)
        self.open.setStyleSheet("QWidget{background-color: rgb(0, 170, 69); border: none;} QToolTip {background-color: white;}")

    def update_status(self, message, timeout = 0):
        """
        Update the status bar with a message.
        """
        _translate = QtCore.QCoreApplication.translate
        self.statusbar.showMessage(_translate("MainWindow", message), timeout)

    def activateOfflineMode(self):
    # Alert user via dialog that the app can't connect to the internet
        self.offline = True             # Offline mode
        dialog = QDialog()
        ui = Ui_Dialog()
        ui.setupUi(dialog)
        ui.setDialogDetails(dialog, 
                            title="Offline Mode", 
                            text="Can't connect to the Internet! \nEntering offline mode.", 
                            textColor="#B41C2B")
        dialog.exec()

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "FiberWatch"))
        self.title_label.setText(_translate("MainWindow", "FiberWatch"))
        self.label_2.setText(_translate("MainWindow", "File"))
        self.label_3.setText(_translate("MainWindow", "Detections"))
        self.open.setToolTip(_translate("MainWindow", "Loads an image for processing by the abaca fiber classification model."))
        self.open.setText(_translate("MainWindow", "Open"))
        self.predict.setToolTip(_translate("MainWindow", "Generates predictions based on the loaded image."))
        self.predict.setText(_translate("MainWindow", "Predict!"))
        __sortingEnabled = self.listWidget.isSortingEnabled()
        self.listWidget.setSortingEnabled(False)
        item = self.listWidget.item(0)
        item.setText(_translate("MainWindow", "Open Image"))
        item = self.listWidget.item(1)
        item.setText(_translate("MainWindow", "Open Video"))
        self.listWidget.setSortingEnabled(__sortingEnabled)

    def closeEvent(self, event):
        """
        Override the closeEvent to execute custom logic before closing.
        """
        # Show a confirmation dialog
        reply = QMessageBox.question(
            self,
            "Confirm Exit",
            "<p style='font-family: Satoshi Bold; font-size: 12pt'>Are you sure you want to exit?</p>",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No,
        )

        if ((self.offline == False) and (reply == QMessageBox.StandardButton.Yes)):
            # Perform any cleanup or save operations here
            print("Application is closing. Cleaning up...")
            
            try:
                # Set system status to offline
                response = (
                            self.supabase.table("system_status")
                            .insert({"online": False, "alert_code": 102})
                            .execute()
                        )
                if self.video_cap != None:
                    self.video_cap.release()
            except:
                event.accept()
                return
            
            event.accept()  # Accept the event and close the application
        else:
            event.ignore()  # Ignore the event and keep the application open

def AlertImage():
    # Alert user via dialog that an image needs to be loaded
    dialog = QDialog()
    ui = Ui_Dialog()
    ui.setupUi(dialog)
    ui.setDialogDetails(dialog, title="Image loading failed!", text="Image must be loaded first!", textColor="#B41C2B")
    dialog.exec()

def AlertVideo():
    # Alert user via dialog that a video needs to be loaded
    dialog = QDialog()
    ui = Ui_Dialog()
    ui.setupUi(dialog)
    ui.setDialogDetails(dialog, title="Video loading failed!", text="Video must be loaded first!", textColor="#B41C2B")
    dialog.exec()

def AlertPrediction():
    # Alert user via dialog that the predictions can't be uploaded
    dialog = QDialog()
    ui = Ui_Dialog()
    ui.setupUi(dialog)
    ui.setDialogDetails(dialog, 
                        title="No Internet Connection", 
                        text="Cannot upload results to online database. \nPlease check your Internet connection \nand try again.", 
                        textColor="#B41C2B")
    dialog.exec()

def AlertNoItemLoaded():
    # Alert user via dialog that the predictions can't be uploaded
    dialog = QDialog()
    ui = Ui_Dialog()
    ui.setupUi(dialog)
    ui.setDialogDetails(dialog, 
                        title="No image or video loaded!", 
                        text="Please load an image or video first!", 
                        textColor="#B41C2B")
    dialog.exec()

class Dialog(QtWidgets.QDialog, Ui_Dialog):
    def __init__(self, *args, obj=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.setupUi(self)

        
